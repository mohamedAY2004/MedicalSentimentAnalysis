{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bNepuETTF5N7"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('medical_tc_train.csv')\n",
    "df_test = pd.read_csv('medical_tc_test.csv')\n",
    "print(df.shape)\n",
    "print(df.head())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iz0KZjPHGPtY",
    "outputId": "3c79853b-5d44-4c12-f0f8-20acbb00e1e6"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(11550, 2)\n",
      "   label                                               text\n",
      "0      5  Tissue changes around loose prostheses. A cani...\n",
      "1      1  Neuropeptide Y and neuron-specific enolase lev...\n",
      "2      2  Sexually transmitted diseases of the colon, re...\n",
      "3      1  Lipolytic factors associated with murine and h...\n",
      "4      3  Does carotid restenosis predict an increased r...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(df_test.shape)\n",
    "print(df_test.head())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3v8PbcAJJqs",
    "outputId": "4d8c989a-d98d-44db-d083-92b250e8b9ba"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2888, 2)\n",
      "   label                                               text\n",
      "0      3  Obstructive sleep apnea following topical orop...\n",
      "1      5  Neutrophil function and pyogenic infections in...\n",
      "2      5  A phase II study of combined methotrexate and ...\n",
      "3      1  Flow cytometric DNA analysis of parathyroid tu...\n",
      "4      4  Paraneoplastic vasculitic neuropathy: a treata...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "RGdEkZGJLGDz",
    "outputId": "87926797-d48f-4e37-babf-a6ea195704a1"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "label    0\n",
       "text     0\n",
       "dtype: int64"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_test.isna().sum()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "ZwS6uKsSJQLY",
    "outputId": "05344bca-30fd-42b7-d3e8-33e0091dedee"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "label    0\n",
       "text     0\n",
       "dtype: int64"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Classes:\", df['label'].unique())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zz2oDQ7FI7Df",
    "outputId": "cba797d2-e381-458d-8d82-c6641d98af11"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classes: [5 1 2 3 4]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Classes:\", df_test['label'].unique())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwvNwN_uJU2B",
    "outputId": "9c74557c-7074-4d54-aba8-038f2a7b1489"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classes: [3 5 1 4 2]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df['label'].value_counts()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "fNIQ_rT1IUzP",
    "outputId": "ac3e1470-5db3-4ece-c9a9-8701bcaf78d3"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "label\n",
       "5    3844\n",
       "1    2530\n",
       "4    2441\n",
       "3    1540\n",
       "2    1195\n",
       "Name: count, dtype: int64"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_test['label'].value_counts()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "E8RVBHmyJdd7",
    "outputId": "5bdd37c0-f12f-4771-91d4-1ae2eafab358"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "label\n",
       "5    961\n",
       "1    633\n",
       "4    610\n",
       "3    385\n",
       "2    299\n",
       "Name: count, dtype: int64"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df = df[df[\"text\"].str.strip() != \"\"]  # remove empty strings\n",
    "df_test = df_test[df_test[\"text\"].str.strip() != \"\"]  # remove empty strings\n",
    "# Split the dataset\n",
    "X_train_texts, X_test_texts=df[\"text\"],df_test[\"text\"]\n",
    "y_train, y_test=df[\"label\"],df_test[\"label\"]\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1"
   ],
   "metadata": {
    "id": "f06tsBVURQ4t"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Pipeline A: TF-IDF + Classifier (Baseline)**"
   ],
   "metadata": {
    "id": "ctMsr6vvV1RN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,   # limit to top 5000 words (prevents overfitting)\n",
    "    ngram_range=(1, 2),  # include unigrams + bigrams\n",
    "    stop_words='english' # remove common English words\n",
    ")\n",
    "X_train = vectorizer.fit_transform(X_train_texts)\n",
    "X_test = vectorizer.transform(X_test_texts)\n",
    "clf = LogisticRegression(max_iter=2000,class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train)\n",
    "y_predA = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_predA)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_predA))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tyaP5FxARWd3",
    "outputId": "a0f51506-eab5-4c54-e681-bdabcc7d5546"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.599376731301939\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72       633\n",
      "           1       0.48      0.70      0.57       299\n",
      "           2       0.51      0.68      0.58       385\n",
      "           3       0.67      0.74      0.70       610\n",
      "           4       0.57      0.34      0.43       961\n",
      "\n",
      "    accuracy                           0.60      2888\n",
      "   macro avg       0.59      0.64      0.60      2888\n",
      "weighted avg       0.60      0.60      0.59      2888\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLk5ozOoLssz",
    "outputId": "52ecf107-c327-450f-b18c-5778991046f0"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((11550, 5000), (11550,), (2888, 5000), (2888,))"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(input_size,)),\n",
    "    layers.Dense(1024,activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "kEI1PaFcKouu",
    "outputId": "e124f490-d63a-49a5-e5ce-3b3caca91f00"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m5,121,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m5,125\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,121,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,125</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,126,149\u001b[0m (19.55 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,126,149</span> (19.55 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,126,149\u001b[0m (19.55 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,126,149</span> (19.55 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=5,batch_size=1024)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kPkG4JbrLTCO",
    "outputId": "a9bc981c-1d89-48b5-b071-2106ebef25a9"
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.3208 - loss: 1.5493 - val_accuracy: 0.4082 - val_loss: 1.3648\n",
      "Epoch 2/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.4853 - loss: 1.2837 - val_accuracy: 0.5374 - val_loss: 1.1562\n",
      "Epoch 3/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.5974 - loss: 1.0540 - val_accuracy: 0.5699 - val_loss: 1.0265\n",
      "Epoch 4/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.6483 - loss: 0.8946 - val_accuracy: 0.5886 - val_loss: 0.9754\n",
      "Epoch 5/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.6801 - loss: 0.8026 - val_accuracy: 0.5921 - val_loss: 0.9655\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb17a541ee0>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_predA = model.predict(X_test)\n",
    "y_predA.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IwpsngIKRnjD",
    "outputId": "1a5455ca-dbcc-4b09-a934-8a99d8344152"
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 141ms/step\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2888, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_predA=np.argmax(y_predA,axis=1)\n",
    "y_predA.shape\n",
    "acc = accuracy_score(y_test, y_predA)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_predA))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKaznKYeRV-X",
    "outputId": "9c5d81e4-85b6-4bee-8a24-0f7203a84778"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.5921052631578947\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71       633\n",
      "           1       0.55      0.49      0.52       299\n",
      "           2       0.59      0.50      0.54       385\n",
      "           3       0.65      0.68      0.66       610\n",
      "           4       0.50      0.52      0.51       961\n",
      "\n",
      "    accuracy                           0.59      2888\n",
      "   macro avg       0.60      0.58      0.59      2888\n",
      "weighted avg       0.59      0.59      0.59      2888\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Pipeline B: Word2Vec + Classifier (Semantic Baseline)**"
   ],
   "metadata": {
    "id": "fL612o81XrHt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install gensim"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xOoZRBugmoC",
    "outputId": "59a40560-22ad-4936-c83d-dc4e9d3fdf1b"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
      "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: gensim\n",
      "Successfully installed gensim-4.4.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Very Bad because it doesn't know that a single word change full sentence meaning like \"not\" and OOV problem that it doesn't know what to do with it\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"punkt_tab\", quiet=True)\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# simple_preprocess handles lowercasing and basic cleaning\n",
    "sentences = [simple_preprocess(str(text)) for text in X_train_texts]\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "#Embedding model\n",
    "w2v_model = Word2Vec(\n",
    "    vector_size=300,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    sg=1,\n",
    "    workers=num_cores\n",
    ")\n",
    "\n",
    "w2v_model.build_vocab(sentences)\n",
    "w2v_model.train(\n",
    "    corpus_iterable=sentences,\n",
    "    total_examples=w2v_model.corpus_count,\n",
    "    epochs=40\n",
    ")\n",
    "\n",
    "def get_w2v_embedding(text, model, vector_size=300):\n",
    "    \"\"\"Return averaged Word2Vec embedding for a given text.\"\"\"\n",
    "    words = word_tokenize(text.lower())\n",
    "    valid_words = [w for w in words if w in model.wv]\n",
    "    if not valid_words:\n",
    "        return np.zeros(vector_size)\n",
    "    return np.mean(model.wv[valid_words], axis=0)\n"
   ],
   "metadata": {
    "id": "utroUN2NXvx_"
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(sentences))           # should match df rows\n",
    "print(sum(len(s) for s in sentences))  # total number of tokens; must be > 0\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HcJBv7ZNcr7I",
    "outputId": "d6b5e532-1c4e-4e61-b34c-941d3570e1e5"
   },
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "11550\n",
      "1943741\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Vocabulary size:\", len(w2v_model.wv))\n",
    "print(\"Example vector:\", w2v_model.wv['diseases'][:10])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yqNWKmFwc0ND",
    "outputId": "7d5da80f-7200-43a2-8c0f-260cd56dbf80"
   },
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vocabulary size: 23598\n",
      "Example vector: [-0.00068371  0.19418362 -0.10004063  0.08062191 -0.07072804  0.01213332\n",
      " -0.02204221 -0.12990037  0.1998624   0.04341627]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "w2v_model.wv.most_similar('diseases', topn=5)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuegQ8_pdc8N",
    "outputId": "e5739839-0b6e-4feb-ce6b-77ab60cff482"
   },
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('stds', 0.43040764331817627),\n",
       " ('pimas', 0.39186009764671326),\n",
       " ('disease', 0.38095739483833313),\n",
       " ('concurrence', 0.3509458303451538),\n",
       " ('diarrhoeal', 0.34319910407066345)]"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "vec = get_w2v_embedding(\"the cancer is growing fast\", w2v_model)\n",
    "print(vec.shape)  # should be (300,)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLsipxSndjhf",
    "outputId": "161e1f45-fd65-4df4-adf2-747c5c35bd3a"
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(300,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Very Bad because it doesn't know that a single word change full sentence meaning like \"not\"\n",
    "X_train = np.vstack([get_w2v_embedding(t, w2v_model) for t in tqdm(X_train_texts)])\n",
    "X_test  = np.vstack([get_w2v_embedding(t, w2v_model) for t in tqdm(X_test_texts)])\n",
    "clf = LogisticRegression(max_iter=2000,class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train)\n",
    "y_predB = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_predB)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_predB))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86dNYKQtYY15",
    "outputId": "6ecfb78b-104e-4e3d-ce29-54771a407a30"
   },
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 11550/11550 [00:34<00:00, 338.86it/s]\n",
      "100%|██████████| 2888/2888 [00:11<00:00, 258.52it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.6007617728531855\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74       633\n",
      "           1       0.47      0.75      0.58       299\n",
      "           2       0.52      0.71      0.60       385\n",
      "           3       0.64      0.79      0.71       610\n",
      "           4       0.61      0.27      0.38       961\n",
      "\n",
      "    accuracy                           0.60      2888\n",
      "   macro avg       0.59      0.66      0.60      2888\n",
      "weighted avg       0.61      0.60      0.58      2888\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(input_size,)),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "PH-hdsAaUXGO",
    "outputId": "d7c9e4c4-6b31-4bbd-d441-e77bd2eb03fc"
   },
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m1,505\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,505</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,505\u001b[0m (5.88 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,505</span> (5.88 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,505\u001b[0m (5.88 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,505</span> (5.88 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=200,batch_size=1024)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuEqDR84U24L",
    "outputId": "55857489-c867-4370-f835-246319042d34"
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 0.2482 - loss: 1.5791 - val_accuracy: 0.3383 - val_loss: 1.5276\n",
      "Epoch 2/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3358 - loss: 1.5175 - val_accuracy: 0.3338 - val_loss: 1.4950\n",
      "Epoch 3/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3354 - loss: 1.4880 - val_accuracy: 0.3338 - val_loss: 1.4774\n",
      "Epoch 4/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3333 - loss: 1.4736 - val_accuracy: 0.3376 - val_loss: 1.4604\n",
      "Epoch 5/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3477 - loss: 1.4503 - val_accuracy: 0.3566 - val_loss: 1.4439\n",
      "Epoch 6/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3666 - loss: 1.4352 - val_accuracy: 0.3684 - val_loss: 1.4281\n",
      "Epoch 7/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3834 - loss: 1.4194 - val_accuracy: 0.3902 - val_loss: 1.4128\n",
      "Epoch 8/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4032 - loss: 1.4053 - val_accuracy: 0.4086 - val_loss: 1.3980\n",
      "Epoch 9/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4246 - loss: 1.3861 - val_accuracy: 0.4166 - val_loss: 1.3837\n",
      "Epoch 10/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4368 - loss: 1.3698 - val_accuracy: 0.4346 - val_loss: 1.3700\n",
      "Epoch 11/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4491 - loss: 1.3580 - val_accuracy: 0.4491 - val_loss: 1.3568\n",
      "Epoch 12/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4644 - loss: 1.3416 - val_accuracy: 0.4536 - val_loss: 1.3441\n",
      "Epoch 13/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4685 - loss: 1.3331 - val_accuracy: 0.4678 - val_loss: 1.3319\n",
      "Epoch 14/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4836 - loss: 1.3164 - val_accuracy: 0.4726 - val_loss: 1.3202\n",
      "Epoch 15/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4838 - loss: 1.3121 - val_accuracy: 0.4827 - val_loss: 1.3088\n",
      "Epoch 16/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4953 - loss: 1.2904 - val_accuracy: 0.4830 - val_loss: 1.2978\n",
      "Epoch 17/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4924 - loss: 1.2871 - val_accuracy: 0.4924 - val_loss: 1.2874\n",
      "Epoch 18/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5084 - loss: 1.2723 - val_accuracy: 0.4962 - val_loss: 1.2774\n",
      "Epoch 19/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5148 - loss: 1.2583 - val_accuracy: 0.4958 - val_loss: 1.2677\n",
      "Epoch 20/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5013 - loss: 1.2589 - val_accuracy: 0.4986 - val_loss: 1.2584\n",
      "Epoch 21/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5123 - loss: 1.2436 - val_accuracy: 0.5028 - val_loss: 1.2496\n",
      "Epoch 22/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5171 - loss: 1.2376 - val_accuracy: 0.5031 - val_loss: 1.2409\n",
      "Epoch 23/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5247 - loss: 1.2230 - val_accuracy: 0.5100 - val_loss: 1.2326\n",
      "Epoch 24/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5273 - loss: 1.2189 - val_accuracy: 0.5139 - val_loss: 1.2247\n",
      "Epoch 25/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5256 - loss: 1.2100 - val_accuracy: 0.5135 - val_loss: 1.2170\n",
      "Epoch 26/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5295 - loss: 1.2017 - val_accuracy: 0.5180 - val_loss: 1.2097\n",
      "Epoch 27/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5327 - loss: 1.1922 - val_accuracy: 0.5235 - val_loss: 1.2026\n",
      "Epoch 28/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5369 - loss: 1.1806 - val_accuracy: 0.5232 - val_loss: 1.1956\n",
      "Epoch 29/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5382 - loss: 1.1806 - val_accuracy: 0.5256 - val_loss: 1.1891\n",
      "Epoch 30/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5388 - loss: 1.1739 - val_accuracy: 0.5263 - val_loss: 1.1826\n",
      "Epoch 31/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5476 - loss: 1.1653 - val_accuracy: 0.5277 - val_loss: 1.1765\n",
      "Epoch 32/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5437 - loss: 1.1626 - val_accuracy: 0.5294 - val_loss: 1.1706\n",
      "Epoch 33/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5471 - loss: 1.1534 - val_accuracy: 0.5319 - val_loss: 1.1650\n",
      "Epoch 34/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5562 - loss: 1.1429 - val_accuracy: 0.5325 - val_loss: 1.1594\n",
      "Epoch 35/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5508 - loss: 1.1442 - val_accuracy: 0.5332 - val_loss: 1.1541\n",
      "Epoch 36/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5499 - loss: 1.1452 - val_accuracy: 0.5336 - val_loss: 1.1489\n",
      "Epoch 37/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5479 - loss: 1.1346 - val_accuracy: 0.5339 - val_loss: 1.1440\n",
      "Epoch 38/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5546 - loss: 1.1278 - val_accuracy: 0.5395 - val_loss: 1.1393\n",
      "Epoch 39/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5609 - loss: 1.1197 - val_accuracy: 0.5433 - val_loss: 1.1346\n",
      "Epoch 40/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5622 - loss: 1.1150 - val_accuracy: 0.5398 - val_loss: 1.1300\n",
      "Epoch 41/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5539 - loss: 1.1229 - val_accuracy: 0.5436 - val_loss: 1.1258\n",
      "Epoch 42/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5711 - loss: 1.1044 - val_accuracy: 0.5416 - val_loss: 1.1216\n",
      "Epoch 43/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5644 - loss: 1.1076 - val_accuracy: 0.5447 - val_loss: 1.1176\n",
      "Epoch 44/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5652 - loss: 1.0954 - val_accuracy: 0.5433 - val_loss: 1.1136\n",
      "Epoch 45/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5686 - loss: 1.0932 - val_accuracy: 0.5485 - val_loss: 1.1099\n",
      "Epoch 46/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5723 - loss: 1.0924 - val_accuracy: 0.5499 - val_loss: 1.1063\n",
      "Epoch 47/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5703 - loss: 1.0856 - val_accuracy: 0.5506 - val_loss: 1.1028\n",
      "Epoch 48/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5750 - loss: 1.0822 - val_accuracy: 0.5516 - val_loss: 1.0993\n",
      "Epoch 49/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5783 - loss: 1.0738 - val_accuracy: 0.5519 - val_loss: 1.0961\n",
      "Epoch 50/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5780 - loss: 1.0731 - val_accuracy: 0.5506 - val_loss: 1.0928\n",
      "Epoch 51/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5787 - loss: 1.0741 - val_accuracy: 0.5557 - val_loss: 1.0898\n",
      "Epoch 52/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5858 - loss: 1.0664 - val_accuracy: 0.5578 - val_loss: 1.0869\n",
      "Epoch 53/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5768 - loss: 1.0690 - val_accuracy: 0.5540 - val_loss: 1.0839\n",
      "Epoch 54/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5796 - loss: 1.0654 - val_accuracy: 0.5578 - val_loss: 1.0812\n",
      "Epoch 55/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5855 - loss: 1.0620 - val_accuracy: 0.5575 - val_loss: 1.0784\n",
      "Epoch 56/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5798 - loss: 1.0619 - val_accuracy: 0.5557 - val_loss: 1.0756\n",
      "Epoch 57/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5799 - loss: 1.0552 - val_accuracy: 0.5561 - val_loss: 1.0731\n",
      "Epoch 58/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5890 - loss: 1.0477 - val_accuracy: 0.5589 - val_loss: 1.0706\n",
      "Epoch 59/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5900 - loss: 1.0488 - val_accuracy: 0.5616 - val_loss: 1.0683\n",
      "Epoch 60/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5848 - loss: 1.0508 - val_accuracy: 0.5609 - val_loss: 1.0659\n",
      "Epoch 61/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5837 - loss: 1.0472 - val_accuracy: 0.5571 - val_loss: 1.0637\n",
      "Epoch 62/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5888 - loss: 1.0396 - val_accuracy: 0.5634 - val_loss: 1.0614\n",
      "Epoch 63/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5918 - loss: 1.0408 - val_accuracy: 0.5668 - val_loss: 1.0595\n",
      "Epoch 64/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5834 - loss: 1.0409 - val_accuracy: 0.5582 - val_loss: 1.0573\n",
      "Epoch 65/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5830 - loss: 1.0396 - val_accuracy: 0.5644 - val_loss: 1.0552\n",
      "Epoch 66/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5908 - loss: 1.0408 - val_accuracy: 0.5644 - val_loss: 1.0532\n",
      "Epoch 67/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5859 - loss: 1.0367 - val_accuracy: 0.5616 - val_loss: 1.0515\n",
      "Epoch 68/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5850 - loss: 1.0413 - val_accuracy: 0.5644 - val_loss: 1.0497\n",
      "Epoch 69/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5846 - loss: 1.0374 - val_accuracy: 0.5623 - val_loss: 1.0477\n",
      "Epoch 70/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5870 - loss: 1.0310 - val_accuracy: 0.5661 - val_loss: 1.0461\n",
      "Epoch 71/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5944 - loss: 1.0246 - val_accuracy: 0.5706 - val_loss: 1.0442\n",
      "Epoch 72/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5924 - loss: 1.0230 - val_accuracy: 0.5637 - val_loss: 1.0427\n",
      "Epoch 73/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5905 - loss: 1.0238 - val_accuracy: 0.5706 - val_loss: 1.0410\n",
      "Epoch 74/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5927 - loss: 1.0193 - val_accuracy: 0.5748 - val_loss: 1.0394\n",
      "Epoch 75/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5981 - loss: 1.0121 - val_accuracy: 0.5686 - val_loss: 1.0379\n",
      "Epoch 76/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5952 - loss: 1.0129 - val_accuracy: 0.5731 - val_loss: 1.0366\n",
      "Epoch 77/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5954 - loss: 1.0156 - val_accuracy: 0.5734 - val_loss: 1.0350\n",
      "Epoch 78/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5921 - loss: 1.0186 - val_accuracy: 0.5710 - val_loss: 1.0336\n",
      "Epoch 79/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5856 - loss: 1.0156 - val_accuracy: 0.5699 - val_loss: 1.0323\n",
      "Epoch 80/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5967 - loss: 1.0072 - val_accuracy: 0.5744 - val_loss: 1.0308\n",
      "Epoch 81/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5935 - loss: 1.0131 - val_accuracy: 0.5724 - val_loss: 1.0295\n",
      "Epoch 82/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5990 - loss: 1.0010 - val_accuracy: 0.5727 - val_loss: 1.0283\n",
      "Epoch 83/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5925 - loss: 1.0129 - val_accuracy: 0.5727 - val_loss: 1.0270\n",
      "Epoch 84/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5985 - loss: 1.0028 - val_accuracy: 0.5758 - val_loss: 1.0259\n",
      "Epoch 85/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5996 - loss: 1.0036 - val_accuracy: 0.5758 - val_loss: 1.0247\n",
      "Epoch 86/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5943 - loss: 1.0098 - val_accuracy: 0.5751 - val_loss: 1.0235\n",
      "Epoch 87/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5985 - loss: 0.9987 - val_accuracy: 0.5748 - val_loss: 1.0223\n",
      "Epoch 88/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5972 - loss: 1.0011 - val_accuracy: 0.5738 - val_loss: 1.0211\n",
      "Epoch 89/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5955 - loss: 1.0015 - val_accuracy: 0.5731 - val_loss: 1.0203\n",
      "Epoch 90/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5951 - loss: 1.0043 - val_accuracy: 0.5772 - val_loss: 1.0193\n",
      "Epoch 91/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6023 - loss: 0.9902 - val_accuracy: 0.5731 - val_loss: 1.0180\n",
      "Epoch 92/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5933 - loss: 0.9990 - val_accuracy: 0.5717 - val_loss: 1.0172\n",
      "Epoch 93/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5971 - loss: 0.9897 - val_accuracy: 0.5744 - val_loss: 1.0161\n",
      "Epoch 94/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5987 - loss: 0.9901 - val_accuracy: 0.5762 - val_loss: 1.0153\n",
      "Epoch 95/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5978 - loss: 0.9918 - val_accuracy: 0.5776 - val_loss: 1.0144\n",
      "Epoch 96/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5922 - loss: 0.9967 - val_accuracy: 0.5738 - val_loss: 1.0135\n",
      "Epoch 97/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6003 - loss: 0.9922 - val_accuracy: 0.5769 - val_loss: 1.0126\n",
      "Epoch 98/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6000 - loss: 0.9920 - val_accuracy: 0.5786 - val_loss: 1.0118\n",
      "Epoch 99/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6060 - loss: 0.9815 - val_accuracy: 0.5765 - val_loss: 1.0109\n",
      "Epoch 100/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5998 - loss: 0.9938 - val_accuracy: 0.5762 - val_loss: 1.0100\n",
      "Epoch 101/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5976 - loss: 0.9918 - val_accuracy: 0.5762 - val_loss: 1.0093\n",
      "Epoch 102/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5975 - loss: 0.9891 - val_accuracy: 0.5772 - val_loss: 1.0088\n",
      "Epoch 103/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5984 - loss: 0.9913 - val_accuracy: 0.5772 - val_loss: 1.0078\n",
      "Epoch 104/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5975 - loss: 0.9893 - val_accuracy: 0.5772 - val_loss: 1.0070\n",
      "Epoch 105/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5997 - loss: 0.9886 - val_accuracy: 0.5786 - val_loss: 1.0061\n",
      "Epoch 106/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6056 - loss: 0.9777 - val_accuracy: 0.5786 - val_loss: 1.0055\n",
      "Epoch 107/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6023 - loss: 0.9801 - val_accuracy: 0.5793 - val_loss: 1.0047\n",
      "Epoch 108/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6076 - loss: 0.9807 - val_accuracy: 0.5803 - val_loss: 1.0040\n",
      "Epoch 109/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6067 - loss: 0.9732 - val_accuracy: 0.5796 - val_loss: 1.0034\n",
      "Epoch 110/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6096 - loss: 0.9781 - val_accuracy: 0.5807 - val_loss: 1.0027\n",
      "Epoch 111/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6038 - loss: 0.9805 - val_accuracy: 0.5803 - val_loss: 1.0020\n",
      "Epoch 112/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6051 - loss: 0.9740 - val_accuracy: 0.5810 - val_loss: 1.0013\n",
      "Epoch 113/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6084 - loss: 0.9730 - val_accuracy: 0.5807 - val_loss: 1.0008\n",
      "Epoch 114/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5972 - loss: 0.9874 - val_accuracy: 0.5796 - val_loss: 1.0002\n",
      "Epoch 115/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6022 - loss: 0.9756 - val_accuracy: 0.5869 - val_loss: 0.9999\n",
      "Epoch 116/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6073 - loss: 0.9760 - val_accuracy: 0.5852 - val_loss: 0.9990\n",
      "Epoch 117/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6048 - loss: 0.9725 - val_accuracy: 0.5800 - val_loss: 0.9985\n",
      "Epoch 118/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6064 - loss: 0.9769 - val_accuracy: 0.5824 - val_loss: 0.9979\n",
      "Epoch 119/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6069 - loss: 0.9782 - val_accuracy: 0.5869 - val_loss: 0.9972\n",
      "Epoch 120/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6028 - loss: 0.9750 - val_accuracy: 0.5838 - val_loss: 0.9967\n",
      "Epoch 121/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6099 - loss: 0.9659 - val_accuracy: 0.5838 - val_loss: 0.9963\n",
      "Epoch 122/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6070 - loss: 0.9700 - val_accuracy: 0.5876 - val_loss: 0.9956\n",
      "Epoch 123/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6078 - loss: 0.9666 - val_accuracy: 0.5876 - val_loss: 0.9951\n",
      "Epoch 124/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6056 - loss: 0.9630 - val_accuracy: 0.5859 - val_loss: 0.9947\n",
      "Epoch 125/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6020 - loss: 0.9804 - val_accuracy: 0.5866 - val_loss: 0.9941\n",
      "Epoch 126/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6061 - loss: 0.9721 - val_accuracy: 0.5880 - val_loss: 0.9936\n",
      "Epoch 127/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6038 - loss: 0.9722 - val_accuracy: 0.5859 - val_loss: 0.9934\n",
      "Epoch 128/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6081 - loss: 0.9664 - val_accuracy: 0.5880 - val_loss: 0.9928\n",
      "Epoch 129/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6062 - loss: 0.9734 - val_accuracy: 0.5869 - val_loss: 0.9924\n",
      "Epoch 130/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6004 - loss: 0.9753 - val_accuracy: 0.5866 - val_loss: 0.9921\n",
      "Epoch 131/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6061 - loss: 0.9628 - val_accuracy: 0.5876 - val_loss: 0.9915\n",
      "Epoch 132/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6042 - loss: 0.9648 - val_accuracy: 0.5880 - val_loss: 0.9908\n",
      "Epoch 133/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6079 - loss: 0.9605 - val_accuracy: 0.5883 - val_loss: 0.9905\n",
      "Epoch 134/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6075 - loss: 0.9606 - val_accuracy: 0.5883 - val_loss: 0.9902\n",
      "Epoch 135/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6090 - loss: 0.9583 - val_accuracy: 0.5880 - val_loss: 0.9899\n",
      "Epoch 136/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6096 - loss: 0.9643 - val_accuracy: 0.5886 - val_loss: 0.9893\n",
      "Epoch 137/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6094 - loss: 0.9648 - val_accuracy: 0.5890 - val_loss: 0.9890\n",
      "Epoch 138/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5997 - loss: 0.9718 - val_accuracy: 0.5886 - val_loss: 0.9884\n",
      "Epoch 139/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6024 - loss: 0.9650 - val_accuracy: 0.5880 - val_loss: 0.9884\n",
      "Epoch 140/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6130 - loss: 0.9638 - val_accuracy: 0.5893 - val_loss: 0.9876\n",
      "Epoch 141/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6108 - loss: 0.9575 - val_accuracy: 0.5886 - val_loss: 0.9873\n",
      "Epoch 142/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6100 - loss: 0.9570 - val_accuracy: 0.5893 - val_loss: 0.9868\n",
      "Epoch 143/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6079 - loss: 0.9607 - val_accuracy: 0.5897 - val_loss: 0.9865\n",
      "Epoch 144/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6050 - loss: 0.9639 - val_accuracy: 0.5897 - val_loss: 0.9862\n",
      "Epoch 145/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6090 - loss: 0.9591 - val_accuracy: 0.5900 - val_loss: 0.9857\n",
      "Epoch 146/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6080 - loss: 0.9612 - val_accuracy: 0.5900 - val_loss: 0.9854\n",
      "Epoch 147/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6098 - loss: 0.9587 - val_accuracy: 0.5890 - val_loss: 0.9853\n",
      "Epoch 148/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6104 - loss: 0.9537 - val_accuracy: 0.5893 - val_loss: 0.9847\n",
      "Epoch 149/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6036 - loss: 0.9659 - val_accuracy: 0.5893 - val_loss: 0.9846\n",
      "Epoch 150/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6078 - loss: 0.9578 - val_accuracy: 0.5897 - val_loss: 0.9843\n",
      "Epoch 151/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6070 - loss: 0.9576 - val_accuracy: 0.5900 - val_loss: 0.9838\n",
      "Epoch 152/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6076 - loss: 0.9586 - val_accuracy: 0.5897 - val_loss: 0.9836\n",
      "Epoch 153/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6114 - loss: 0.9551 - val_accuracy: 0.5907 - val_loss: 0.9833\n",
      "Epoch 154/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6102 - loss: 0.9575 - val_accuracy: 0.5918 - val_loss: 0.9828\n",
      "Epoch 155/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6114 - loss: 0.9579 - val_accuracy: 0.5907 - val_loss: 0.9827\n",
      "Epoch 156/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6125 - loss: 0.9538 - val_accuracy: 0.5907 - val_loss: 0.9823\n",
      "Epoch 157/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6111 - loss: 0.9542 - val_accuracy: 0.5886 - val_loss: 0.9820\n",
      "Epoch 158/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6079 - loss: 0.9581 - val_accuracy: 0.5890 - val_loss: 0.9820\n",
      "Epoch 159/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6048 - loss: 0.9613 - val_accuracy: 0.5914 - val_loss: 0.9813\n",
      "Epoch 160/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6160 - loss: 0.9447 - val_accuracy: 0.5897 - val_loss: 0.9813\n",
      "Epoch 161/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6076 - loss: 0.9589 - val_accuracy: 0.5911 - val_loss: 0.9812\n",
      "Epoch 162/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6136 - loss: 0.9507 - val_accuracy: 0.5893 - val_loss: 0.9807\n",
      "Epoch 163/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6095 - loss: 0.9529 - val_accuracy: 0.5904 - val_loss: 0.9804\n",
      "Epoch 164/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6167 - loss: 0.9423 - val_accuracy: 0.5911 - val_loss: 0.9805\n",
      "Epoch 165/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6124 - loss: 0.9488 - val_accuracy: 0.5893 - val_loss: 0.9800\n",
      "Epoch 166/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6076 - loss: 0.9586 - val_accuracy: 0.5900 - val_loss: 0.9797\n",
      "Epoch 167/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6122 - loss: 0.9491 - val_accuracy: 0.5918 - val_loss: 0.9795\n",
      "Epoch 168/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6100 - loss: 0.9506 - val_accuracy: 0.5893 - val_loss: 0.9795\n",
      "Epoch 169/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6142 - loss: 0.9471 - val_accuracy: 0.5925 - val_loss: 0.9790\n",
      "Epoch 170/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6112 - loss: 0.9437 - val_accuracy: 0.5893 - val_loss: 0.9786\n",
      "Epoch 171/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6117 - loss: 0.9477 - val_accuracy: 0.5897 - val_loss: 0.9787\n",
      "Epoch 172/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6147 - loss: 0.9464 - val_accuracy: 0.5904 - val_loss: 0.9783\n",
      "Epoch 173/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6155 - loss: 0.9455 - val_accuracy: 0.5897 - val_loss: 0.9780\n",
      "Epoch 174/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6121 - loss: 0.9431 - val_accuracy: 0.5897 - val_loss: 0.9778\n",
      "Epoch 175/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6128 - loss: 0.9445 - val_accuracy: 0.5914 - val_loss: 0.9777\n",
      "Epoch 176/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6202 - loss: 0.9398 - val_accuracy: 0.5914 - val_loss: 0.9773\n",
      "Epoch 177/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6179 - loss: 0.9439 - val_accuracy: 0.5897 - val_loss: 0.9773\n",
      "Epoch 178/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6144 - loss: 0.9488 - val_accuracy: 0.5904 - val_loss: 0.9771\n",
      "Epoch 179/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6128 - loss: 0.9361 - val_accuracy: 0.5897 - val_loss: 0.9770\n",
      "Epoch 180/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6122 - loss: 0.9495 - val_accuracy: 0.5904 - val_loss: 0.9768\n",
      "Epoch 181/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6141 - loss: 0.9487 - val_accuracy: 0.5904 - val_loss: 0.9763\n",
      "Epoch 182/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6145 - loss: 0.9439 - val_accuracy: 0.5907 - val_loss: 0.9762\n",
      "Epoch 183/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6084 - loss: 0.9441 - val_accuracy: 0.5907 - val_loss: 0.9760\n",
      "Epoch 184/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6215 - loss: 0.9409 - val_accuracy: 0.5893 - val_loss: 0.9761\n",
      "Epoch 185/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6135 - loss: 0.9437 - val_accuracy: 0.5911 - val_loss: 0.9757\n",
      "Epoch 186/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6064 - loss: 0.9504 - val_accuracy: 0.5914 - val_loss: 0.9753\n",
      "Epoch 187/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6150 - loss: 0.9425 - val_accuracy: 0.5914 - val_loss: 0.9755\n",
      "Epoch 188/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6141 - loss: 0.9477 - val_accuracy: 0.5900 - val_loss: 0.9752\n",
      "Epoch 189/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6152 - loss: 0.9401 - val_accuracy: 0.5907 - val_loss: 0.9751\n",
      "Epoch 190/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6184 - loss: 0.9412 - val_accuracy: 0.5921 - val_loss: 0.9749\n",
      "Epoch 191/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6140 - loss: 0.9431 - val_accuracy: 0.5911 - val_loss: 0.9747\n",
      "Epoch 192/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6085 - loss: 0.9478 - val_accuracy: 0.5907 - val_loss: 0.9746\n",
      "Epoch 193/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6106 - loss: 0.9495 - val_accuracy: 0.5921 - val_loss: 0.9744\n",
      "Epoch 194/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6158 - loss: 0.9362 - val_accuracy: 0.5914 - val_loss: 0.9741\n",
      "Epoch 195/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6181 - loss: 0.9395 - val_accuracy: 0.5914 - val_loss: 0.9741\n",
      "Epoch 196/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6101 - loss: 0.9465 - val_accuracy: 0.5925 - val_loss: 0.9738\n",
      "Epoch 197/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6204 - loss: 0.9363 - val_accuracy: 0.5918 - val_loss: 0.9736\n",
      "Epoch 198/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6148 - loss: 0.9384 - val_accuracy: 0.5914 - val_loss: 0.9735\n",
      "Epoch 199/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6125 - loss: 0.9361 - val_accuracy: 0.5914 - val_loss: 0.9735\n",
      "Epoch 200/200\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6115 - loss: 0.9437 - val_accuracy: 0.5935 - val_loss: 0.9734\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb1625a7e30>"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_predB = model.predict(X_test)\n",
    "y_predB=np.argmax(y_predB,axis=1)\n",
    "y_predB.shape\n",
    "acc = accuracy_score(y_test, y_predB)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_predB))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvN1FY0Xbhza",
    "outputId": "8e852b59-9637-4d3b-e94a-321d594ba9b2"
   },
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Accuracy: 0.5934903047091413\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       633\n",
      "           1       0.55      0.41      0.47       299\n",
      "           2       0.64      0.43      0.51       385\n",
      "           3       0.65      0.71      0.68       610\n",
      "           4       0.49      0.55      0.52       961\n",
      "\n",
      "    accuracy                           0.59      2888\n",
      "   macro avg       0.61      0.57      0.58      2888\n",
      "weighted avg       0.60      0.59      0.59      2888\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Pipeline C: Pre-trained Transformer Embedder + Classifier**"
   ],
   "metadata": {
    "id": "3HHg7ARDWBdN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\")\n",
    "model = AutoModel.from_pretrained(\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "4301df440441405da3889cd85a1fc6cf",
      "bc536bf5a71740de9ebe7a0a8ee6189c",
      "eb1b5ec68151406094d7e3226f5e443a",
      "fd400b811f0343f2bec46353647de850",
      "a464261b1c80445199adb75f14dc1eb7",
      "d54b7cc3a28848d5af924cec44288a99",
      "8e246a0c8a2b4932bac8ffd357016a44",
      "49c33cfecebf4096b8a9c14d61340d4f",
      "90f1182a487448c0b9b042a3c870ba06",
      "5b1537af1ee44ecd89e12f421b475891",
      "b6e87de5e97241cca1411951fa674da6",
      "cfc5ac1ae0654a2296451bc1d2256cc4",
      "cab85b520cb04a9ab991f49fb028370a",
      "92965d965e324a33bd6ec550eb8ab1f6",
      "e940f690902b48a280d08f3eeab10925",
      "1d65b9343dbe4733a8477520cda5954c",
      "d916267dd9294ee5ad24ac2784893ecb",
      "396af821953b43808b783c0821594e94",
      "be0ffba995544867af0125b2a85f95e6",
      "3528b620420347b08405d0564056f788",
      "3c6e41a9cca84b8d8359a3c60f1354b4",
      "8d1e348831e145f280425e229ebbb570",
      "bbbdd9eb842647deae8dddf5abf65e90",
      "608fa2a1ef7847d2ad32657acbebf501",
      "bb48c9a77db5403da4bb704d8711b060",
      "f9099575da4b4d949c6e2cb3d42369bf",
      "554e3aff26b04ca29a44327006597c98",
      "617298f8efaf470aaa52a5c9fae946b1",
      "ed0c9a537ec94ef8b57f8a6031149e69",
      "7b720139a640490aa2b59c4addd20994",
      "ff278495abb645d7bed491e5680c3582",
      "9b9c0ab4c07d4c18b1127615b86ebbb2",
      "f77c6168352340d5adef05406cbc6c22",
      "bfc9072e470d4f7e96a5a8b0e8a6fd19",
      "9f8559d4b34d4293addf49c38f248783",
      "2157c0aaeb8e409e8e3ce1d5c47ee49d",
      "cf6a6d763b0e4551bc2f46f1a72f4573",
      "e60cda6dbd1645809a11266ea58dc09f",
      "d80b9155fc88492abfc95d9aef12a3e9",
      "8e58e9660b0244ccbb163d3a6564aa16",
      "30a78802154c4da69800ce385c315347",
      "1e223c5d34a6427287e386beb876134e",
      "87bec69173544427875e1c1698d7cc5b",
      "d120ccba825d4aeabf5f5abda8f70614",
      "0f62adbac7f54cd0aab1681b210268f4",
      "4194384957d14ecaa5b828d189817fec",
      "d30cda0b1580444597775d01d79f3811",
      "169b6e119ffd4c60873c98c4d02883cc",
      "33dc15fdf8dc4d818669f83da6816bde",
      "b0fe801d6e234ca9acdb865408c35555",
      "d649791b76fa4d32a39baa5f664538bb",
      "cd781a0c7f404b1698f7e000da841b35",
      "a528ce2ea517489da5b27498e76296cc",
      "c3884afef51047a1943f9dfd4075a9b0",
      "17deccae9cf54ca09da8bb1f73449ac1"
     ]
    },
    "id": "ymVn0UMPI-gZ",
    "outputId": "e01f1039-346e-49e1-8ea7-677de36e64bb"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/198 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/462 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def clean_texts(texts):\n",
    "    \"\"\"\n",
    "    Ensures all items are strings and removes NaNs or None.\n",
    "    \"\"\"\n",
    "    # Convert to pandas Series for easy cleaning\n",
    "    s = pd.Series(texts).dropna().astype(str)\n",
    "    return s.tolist()\n",
    "\n",
    "def get_embeddings_batch(texts, batch_size=16, pooling=\"cls\", max_length=256):\n",
    "    texts = clean_texts(texts)\n",
    "    all_embeddings = []\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.to(\"cuda\")\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            if pooling == \"mean\":\n",
    "                batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "            else:\n",
    "                batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(all_embeddings)\n"
   ],
   "metadata": {
    "id": "vaet75vuJLWT"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Using CLS token embedding\n",
    "X_train = get_embeddings_batch(X_train_texts, batch_size=128)\n",
    "X_test = get_embeddings_batch(X_test_texts, batch_size=128)\n",
    "clf = LogisticRegression(max_iter=2000,class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FlR7GkQHJStf",
    "outputId": "b221615e-3444-48c0-b4e5-7a855f9510c8"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 91/91 [02:45<00:00,  1.82s/it]\n",
      "100%|██████████| 23/23 [00:40<00:00,  1.77s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.5858725761772853\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72       633\n",
      "           1       0.46      0.70      0.55       299\n",
      "           2       0.52      0.66      0.58       385\n",
      "           3       0.63      0.76      0.69       610\n",
      "           4       0.56      0.30      0.39       961\n",
      "\n",
      "    accuracy                           0.59      2888\n",
      "   macro avg       0.57      0.63      0.59      2888\n",
      "weighted avg       0.59      0.59      0.57      2888\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "input_size = X_train.shape[1]\n",
    "\n",
    "clf = models.Sequential([\n",
    "    layers.Input(shape=(input_size,)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "clf.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "clf.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "1WooXtmGjL3L",
    "outputId": "070b937e-6229-40cb-ce48-0893493552ef"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m3,845\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,845\u001b[0m (15.02 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> (15.02 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,845\u001b[0m (15.02 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> (15.02 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "clf.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=1024)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FNkmSrQujHVD",
    "outputId": "0114b603-9925-4013-e656-19ea5b79c718"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - accuracy: 0.2450 - loss: 1.8489 - val_accuracy: 0.4062 - val_loss: 1.3754\n",
      "Epoch 2/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3812 - loss: 1.5002 - val_accuracy: 0.5194 - val_loss: 1.1758\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4559 - loss: 1.2996 - val_accuracy: 0.5544 - val_loss: 1.0709\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5020 - loss: 1.1863 - val_accuracy: 0.5731 - val_loss: 1.0132\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5429 - loss: 1.1087 - val_accuracy: 0.5855 - val_loss: 0.9797\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5565 - loss: 1.0739 - val_accuracy: 0.5928 - val_loss: 0.9589\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5642 - loss: 1.0502 - val_accuracy: 0.6011 - val_loss: 0.9435\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5685 - loss: 1.0291 - val_accuracy: 0.6028 - val_loss: 0.9318\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5846 - loss: 1.0100 - val_accuracy: 0.6032 - val_loss: 0.9239\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5904 - loss: 0.9883 - val_accuracy: 0.6084 - val_loss: 0.9180\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5961 - loss: 0.9697 - val_accuracy: 0.6080 - val_loss: 0.9122\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5985 - loss: 0.9603 - val_accuracy: 0.6101 - val_loss: 0.9074\n",
      "Epoch 13/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5915 - loss: 0.9724 - val_accuracy: 0.6111 - val_loss: 0.9031\n",
      "Epoch 14/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5992 - loss: 0.9596 - val_accuracy: 0.6115 - val_loss: 0.9011\n",
      "Epoch 15/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6005 - loss: 0.9611 - val_accuracy: 0.6146 - val_loss: 0.8982\n",
      "Epoch 16/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6013 - loss: 0.9427 - val_accuracy: 0.6129 - val_loss: 0.8968\n",
      "Epoch 17/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6017 - loss: 0.9526 - val_accuracy: 0.6132 - val_loss: 0.8944\n",
      "Epoch 18/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6055 - loss: 0.9372 - val_accuracy: 0.6129 - val_loss: 0.8932\n",
      "Epoch 19/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6099 - loss: 0.9380 - val_accuracy: 0.6132 - val_loss: 0.8908\n",
      "Epoch 20/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6009 - loss: 0.9348 - val_accuracy: 0.6163 - val_loss: 0.8904\n",
      "Epoch 21/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6133 - loss: 0.9271 - val_accuracy: 0.6136 - val_loss: 0.8883\n",
      "Epoch 22/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6058 - loss: 0.9371 - val_accuracy: 0.6125 - val_loss: 0.8870\n",
      "Epoch 23/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6071 - loss: 0.9205 - val_accuracy: 0.6181 - val_loss: 0.8855\n",
      "Epoch 24/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6162 - loss: 0.9120 - val_accuracy: 0.6125 - val_loss: 0.8844\n",
      "Epoch 25/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6087 - loss: 0.9239 - val_accuracy: 0.6219 - val_loss: 0.8848\n",
      "Epoch 26/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6179 - loss: 0.9170 - val_accuracy: 0.6098 - val_loss: 0.8829\n",
      "Epoch 27/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6148 - loss: 0.9119 - val_accuracy: 0.6163 - val_loss: 0.8816\n",
      "Epoch 28/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6181 - loss: 0.9176 - val_accuracy: 0.6111 - val_loss: 0.8816\n",
      "Epoch 29/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6184 - loss: 0.9094 - val_accuracy: 0.6153 - val_loss: 0.8812\n",
      "Epoch 30/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6124 - loss: 0.9119 - val_accuracy: 0.6167 - val_loss: 0.8822\n",
      "Epoch 31/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6189 - loss: 0.9081 - val_accuracy: 0.6111 - val_loss: 0.8808\n",
      "Epoch 32/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6169 - loss: 0.9028 - val_accuracy: 0.6198 - val_loss: 0.8803\n",
      "Epoch 33/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6251 - loss: 0.8944 - val_accuracy: 0.6160 - val_loss: 0.8799\n",
      "Epoch 34/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6230 - loss: 0.9134 - val_accuracy: 0.6098 - val_loss: 0.8801\n",
      "Epoch 35/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6166 - loss: 0.9090 - val_accuracy: 0.6146 - val_loss: 0.8809\n",
      "Epoch 36/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6283 - loss: 0.8965 - val_accuracy: 0.6150 - val_loss: 0.8803\n",
      "Epoch 37/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6190 - loss: 0.9043 - val_accuracy: 0.6125 - val_loss: 0.8801\n",
      "Epoch 38/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6207 - loss: 0.9065 - val_accuracy: 0.6125 - val_loss: 0.8784\n",
      "Epoch 39/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6167 - loss: 0.9176 - val_accuracy: 0.6163 - val_loss: 0.8791\n",
      "Epoch 40/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6263 - loss: 0.8937 - val_accuracy: 0.6181 - val_loss: 0.8784\n",
      "Epoch 41/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6294 - loss: 0.8938 - val_accuracy: 0.6143 - val_loss: 0.8788\n",
      "Epoch 42/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6227 - loss: 0.8987 - val_accuracy: 0.6163 - val_loss: 0.8797\n",
      "Epoch 43/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6200 - loss: 0.9052 - val_accuracy: 0.6105 - val_loss: 0.8806\n",
      "Epoch 44/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6148 - loss: 0.8989 - val_accuracy: 0.6212 - val_loss: 0.8795\n",
      "Epoch 45/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6201 - loss: 0.9111 - val_accuracy: 0.6153 - val_loss: 0.8777\n",
      "Epoch 46/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6185 - loss: 0.8968 - val_accuracy: 0.6157 - val_loss: 0.8775\n",
      "Epoch 47/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6252 - loss: 0.8876 - val_accuracy: 0.6219 - val_loss: 0.8782\n",
      "Epoch 48/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6213 - loss: 0.8955 - val_accuracy: 0.6212 - val_loss: 0.8771\n",
      "Epoch 49/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6153 - loss: 0.9068 - val_accuracy: 0.6163 - val_loss: 0.8769\n",
      "Epoch 50/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6173 - loss: 0.9136 - val_accuracy: 0.6219 - val_loss: 0.8761\n",
      "Epoch 51/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6196 - loss: 0.8963 - val_accuracy: 0.6129 - val_loss: 0.8770\n",
      "Epoch 52/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6213 - loss: 0.8947 - val_accuracy: 0.6205 - val_loss: 0.8777\n",
      "Epoch 53/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6181 - loss: 0.8967 - val_accuracy: 0.6143 - val_loss: 0.8787\n",
      "Epoch 54/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6254 - loss: 0.8845 - val_accuracy: 0.6098 - val_loss: 0.8786\n",
      "Epoch 55/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6264 - loss: 0.8924 - val_accuracy: 0.6163 - val_loss: 0.8782\n",
      "Epoch 56/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6182 - loss: 0.9042 - val_accuracy: 0.6063 - val_loss: 0.8784\n",
      "Epoch 57/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6244 - loss: 0.8972 - val_accuracy: 0.6157 - val_loss: 0.8781\n",
      "Epoch 58/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6193 - loss: 0.8915 - val_accuracy: 0.6184 - val_loss: 0.8784\n",
      "Epoch 59/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6150 - loss: 0.9121 - val_accuracy: 0.6150 - val_loss: 0.8781\n",
      "Epoch 60/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6198 - loss: 0.9052 - val_accuracy: 0.6098 - val_loss: 0.8775\n",
      "Epoch 61/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6089 - loss: 0.9019 - val_accuracy: 0.6160 - val_loss: 0.8773\n",
      "Epoch 62/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6143 - loss: 0.9040 - val_accuracy: 0.6139 - val_loss: 0.8778\n",
      "Epoch 63/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6192 - loss: 0.9001 - val_accuracy: 0.6177 - val_loss: 0.8779\n",
      "Epoch 64/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6153 - loss: 0.9048 - val_accuracy: 0.6170 - val_loss: 0.8777\n",
      "Epoch 65/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6304 - loss: 0.8834 - val_accuracy: 0.6150 - val_loss: 0.8767\n",
      "Epoch 66/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6207 - loss: 0.9013 - val_accuracy: 0.6167 - val_loss: 0.8770\n",
      "Epoch 67/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6123 - loss: 0.9098 - val_accuracy: 0.6108 - val_loss: 0.8765\n",
      "Epoch 68/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6125 - loss: 0.8967 - val_accuracy: 0.6101 - val_loss: 0.8757\n",
      "Epoch 69/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6219 - loss: 0.8961 - val_accuracy: 0.6136 - val_loss: 0.8770\n",
      "Epoch 70/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6229 - loss: 0.8848 - val_accuracy: 0.6198 - val_loss: 0.8764\n",
      "Epoch 71/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6170 - loss: 0.9005 - val_accuracy: 0.6143 - val_loss: 0.8763\n",
      "Epoch 72/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6219 - loss: 0.8850 - val_accuracy: 0.6177 - val_loss: 0.8756\n",
      "Epoch 73/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6187 - loss: 0.8999 - val_accuracy: 0.6184 - val_loss: 0.8772\n",
      "Epoch 74/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6182 - loss: 0.8998 - val_accuracy: 0.6174 - val_loss: 0.8757\n",
      "Epoch 75/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6184 - loss: 0.8977 - val_accuracy: 0.6146 - val_loss: 0.8762\n",
      "Epoch 76/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6246 - loss: 0.8907 - val_accuracy: 0.6163 - val_loss: 0.8758\n",
      "Epoch 77/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6229 - loss: 0.8946 - val_accuracy: 0.6157 - val_loss: 0.8754\n",
      "Epoch 78/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6238 - loss: 0.8879 - val_accuracy: 0.6219 - val_loss: 0.8763\n",
      "Epoch 79/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6205 - loss: 0.9032 - val_accuracy: 0.6157 - val_loss: 0.8752\n",
      "Epoch 80/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6230 - loss: 0.8879 - val_accuracy: 0.6177 - val_loss: 0.8751\n",
      "Epoch 81/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6155 - loss: 0.8962 - val_accuracy: 0.6136 - val_loss: 0.8752\n",
      "Epoch 82/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6189 - loss: 0.8928 - val_accuracy: 0.6191 - val_loss: 0.8751\n",
      "Epoch 83/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6127 - loss: 0.9063 - val_accuracy: 0.6170 - val_loss: 0.8748\n",
      "Epoch 84/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6275 - loss: 0.8977 - val_accuracy: 0.6174 - val_loss: 0.8750\n",
      "Epoch 85/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6166 - loss: 0.9027 - val_accuracy: 0.6129 - val_loss: 0.8755\n",
      "Epoch 86/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6220 - loss: 0.8959 - val_accuracy: 0.6184 - val_loss: 0.8755\n",
      "Epoch 87/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6231 - loss: 0.8842 - val_accuracy: 0.6184 - val_loss: 0.8758\n",
      "Epoch 88/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6161 - loss: 0.9045 - val_accuracy: 0.6205 - val_loss: 0.8783\n",
      "Epoch 89/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6273 - loss: 0.8815 - val_accuracy: 0.6125 - val_loss: 0.8774\n",
      "Epoch 90/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6245 - loss: 0.8917 - val_accuracy: 0.6132 - val_loss: 0.8753\n",
      "Epoch 91/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6233 - loss: 0.8890 - val_accuracy: 0.6157 - val_loss: 0.8753\n",
      "Epoch 92/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6205 - loss: 0.8909 - val_accuracy: 0.6160 - val_loss: 0.8754\n",
      "Epoch 93/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6246 - loss: 0.8870 - val_accuracy: 0.6170 - val_loss: 0.8736\n",
      "Epoch 94/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6261 - loss: 0.8918 - val_accuracy: 0.6229 - val_loss: 0.8745\n",
      "Epoch 95/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6208 - loss: 0.8902 - val_accuracy: 0.6174 - val_loss: 0.8754\n",
      "Epoch 96/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6170 - loss: 0.8939 - val_accuracy: 0.6229 - val_loss: 0.8749\n",
      "Epoch 97/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6281 - loss: 0.8911 - val_accuracy: 0.6139 - val_loss: 0.8741\n",
      "Epoch 98/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6135 - loss: 0.9102 - val_accuracy: 0.6150 - val_loss: 0.8730\n",
      "Epoch 99/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6157 - loss: 0.8912 - val_accuracy: 0.6188 - val_loss: 0.8741\n",
      "Epoch 100/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6209 - loss: 0.8961 - val_accuracy: 0.6143 - val_loss: 0.8746\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb179699730>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred=np.argmax(y_pred,axis=1)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXquA7C1j2Ar",
    "outputId": "96e82daa-8d5b-45f4-c9b0-1873781cd1d0"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Accuracy: 0.6142659279778393\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.74       633\n",
      "           1       0.55      0.52      0.53       299\n",
      "           2       0.61      0.52      0.56       385\n",
      "           3       0.66      0.74      0.70       610\n",
      "           4       0.52      0.49      0.51       961\n",
      "\n",
      "    accuracy                           0.61      2888\n",
      "   macro avg       0.61      0.61      0.61      2888\n",
      "weighted avg       0.61      0.61      0.61      2888\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Using mean pooling embedding\n",
    "X_train = get_embeddings_batch(X_train_texts, batch_size=128,pooling=\"mean\")\n",
    "X_test = get_embeddings_batch(X_test_texts, batch_size=128,pooling=\"mean\")\n",
    "clf = LogisticRegression(max_iter=2000,class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train)\n",
    "y_predC = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_predC)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLCKLzxZU1qc",
    "outputId": "e845d313-2178-497a-ae7f-f19a1339bbbb"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 91/91 [02:42<00:00,  1.79s/it]\n",
      "100%|██████████| 23/23 [00:40<00:00,  1.75s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.5772160664819944\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.74       633\n",
      "           1       0.55      0.52      0.53       299\n",
      "           2       0.61      0.52      0.56       385\n",
      "           3       0.66      0.74      0.70       610\n",
      "           4       0.52      0.49      0.51       961\n",
      "\n",
      "    accuracy                           0.61      2888\n",
      "   macro avg       0.61      0.61      0.61      2888\n",
      "weighted avg       0.61      0.61      0.61      2888\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "input_size = X_train.shape[1]\n",
    "\n",
    "clf = models.Sequential([\n",
    "    layers.Input(shape=(input_size,)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "clf.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "clf.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "vrqLv6mik9EG",
    "outputId": "a1f74eb4-5b13-4391-c3b1-0e8332f3d454"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m3,845\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,845\u001b[0m (15.02 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> (15.02 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,845\u001b[0m (15.02 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> (15.02 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "clf.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=1024)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWVOB7XolGiV",
    "outputId": "68eee599-550f-4731-8169-40d7a1690bc9"
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 0.2298 - loss: 1.9938 - val_accuracy: 0.3961 - val_loss: 1.4174\n",
      "Epoch 2/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3658 - loss: 1.5777 - val_accuracy: 0.4778 - val_loss: 1.2331\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4369 - loss: 1.3707 - val_accuracy: 0.5429 - val_loss: 1.1223\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4885 - loss: 1.2389 - val_accuracy: 0.5571 - val_loss: 1.0519\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5179 - loss: 1.1592 - val_accuracy: 0.5744 - val_loss: 1.0120\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5455 - loss: 1.0959 - val_accuracy: 0.5814 - val_loss: 0.9825\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5522 - loss: 1.0694 - val_accuracy: 0.5845 - val_loss: 0.9635\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5782 - loss: 1.0248 - val_accuracy: 0.5931 - val_loss: 0.9496\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5767 - loss: 1.0242 - val_accuracy: 0.5938 - val_loss: 0.9396\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5787 - loss: 1.0062 - val_accuracy: 0.6025 - val_loss: 0.9315\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5857 - loss: 0.9954 - val_accuracy: 0.6011 - val_loss: 0.9248\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5788 - loss: 0.9912 - val_accuracy: 0.6084 - val_loss: 0.9192\n",
      "Epoch 13/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5918 - loss: 0.9775 - val_accuracy: 0.6053 - val_loss: 0.9141\n",
      "Epoch 14/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6008 - loss: 0.9537 - val_accuracy: 0.6087 - val_loss: 0.9105\n",
      "Epoch 15/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5878 - loss: 0.9710 - val_accuracy: 0.6087 - val_loss: 0.9068\n",
      "Epoch 16/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5981 - loss: 0.9611 - val_accuracy: 0.6077 - val_loss: 0.9042\n",
      "Epoch 17/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6069 - loss: 0.9480 - val_accuracy: 0.6084 - val_loss: 0.9019\n",
      "Epoch 18/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6107 - loss: 0.9252 - val_accuracy: 0.6094 - val_loss: 0.8990\n",
      "Epoch 19/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5986 - loss: 0.9499 - val_accuracy: 0.6115 - val_loss: 0.8976\n",
      "Epoch 20/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6086 - loss: 0.9395 - val_accuracy: 0.6098 - val_loss: 0.8950\n",
      "Epoch 21/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6113 - loss: 0.9316 - val_accuracy: 0.6111 - val_loss: 0.8936\n",
      "Epoch 22/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6033 - loss: 0.9379 - val_accuracy: 0.6111 - val_loss: 0.8921\n",
      "Epoch 23/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6093 - loss: 0.9306 - val_accuracy: 0.6136 - val_loss: 0.8913\n",
      "Epoch 24/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6044 - loss: 0.9358 - val_accuracy: 0.6105 - val_loss: 0.8898\n",
      "Epoch 25/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6180 - loss: 0.9151 - val_accuracy: 0.6163 - val_loss: 0.8896\n",
      "Epoch 26/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6048 - loss: 0.9333 - val_accuracy: 0.6129 - val_loss: 0.8881\n",
      "Epoch 27/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6058 - loss: 0.9170 - val_accuracy: 0.6125 - val_loss: 0.8876\n",
      "Epoch 28/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6146 - loss: 0.9155 - val_accuracy: 0.6122 - val_loss: 0.8867\n",
      "Epoch 29/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6075 - loss: 0.9253 - val_accuracy: 0.6136 - val_loss: 0.8854\n",
      "Epoch 30/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6149 - loss: 0.9093 - val_accuracy: 0.6129 - val_loss: 0.8856\n",
      "Epoch 31/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6077 - loss: 0.9241 - val_accuracy: 0.6146 - val_loss: 0.8856\n",
      "Epoch 32/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6132 - loss: 0.9165 - val_accuracy: 0.6122 - val_loss: 0.8847\n",
      "Epoch 33/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6096 - loss: 0.9230 - val_accuracy: 0.6139 - val_loss: 0.8836\n",
      "Epoch 34/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6152 - loss: 0.9094 - val_accuracy: 0.6108 - val_loss: 0.8831\n",
      "Epoch 35/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6136 - loss: 0.9210 - val_accuracy: 0.6129 - val_loss: 0.8827\n",
      "Epoch 36/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6236 - loss: 0.8969 - val_accuracy: 0.6122 - val_loss: 0.8821\n",
      "Epoch 37/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6138 - loss: 0.9030 - val_accuracy: 0.6125 - val_loss: 0.8827\n",
      "Epoch 38/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6124 - loss: 0.9196 - val_accuracy: 0.6129 - val_loss: 0.8822\n",
      "Epoch 39/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6197 - loss: 0.9037 - val_accuracy: 0.6150 - val_loss: 0.8816\n",
      "Epoch 40/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6183 - loss: 0.9103 - val_accuracy: 0.6143 - val_loss: 0.8812\n",
      "Epoch 41/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6196 - loss: 0.9017 - val_accuracy: 0.6150 - val_loss: 0.8805\n",
      "Epoch 42/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6072 - loss: 0.9194 - val_accuracy: 0.6177 - val_loss: 0.8822\n",
      "Epoch 43/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6211 - loss: 0.9065 - val_accuracy: 0.6118 - val_loss: 0.8826\n",
      "Epoch 44/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6113 - loss: 0.9130 - val_accuracy: 0.6125 - val_loss: 0.8819\n",
      "Epoch 45/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6238 - loss: 0.9040 - val_accuracy: 0.6118 - val_loss: 0.8812\n",
      "Epoch 46/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6212 - loss: 0.9030 - val_accuracy: 0.6150 - val_loss: 0.8807\n",
      "Epoch 47/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6179 - loss: 0.8938 - val_accuracy: 0.6191 - val_loss: 0.8811\n",
      "Epoch 48/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6190 - loss: 0.9003 - val_accuracy: 0.6115 - val_loss: 0.8810\n",
      "Epoch 49/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6185 - loss: 0.8988 - val_accuracy: 0.6170 - val_loss: 0.8811\n",
      "Epoch 50/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6204 - loss: 0.8978 - val_accuracy: 0.6146 - val_loss: 0.8806\n",
      "Epoch 51/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6063 - loss: 0.9128 - val_accuracy: 0.6163 - val_loss: 0.8804\n",
      "Epoch 52/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6183 - loss: 0.9012 - val_accuracy: 0.6115 - val_loss: 0.8808\n",
      "Epoch 53/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6250 - loss: 0.8940 - val_accuracy: 0.6195 - val_loss: 0.8802\n",
      "Epoch 54/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6220 - loss: 0.8963 - val_accuracy: 0.6143 - val_loss: 0.8809\n",
      "Epoch 55/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6205 - loss: 0.9022 - val_accuracy: 0.6139 - val_loss: 0.8796\n",
      "Epoch 56/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6212 - loss: 0.9066 - val_accuracy: 0.6157 - val_loss: 0.8794\n",
      "Epoch 57/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6243 - loss: 0.8879 - val_accuracy: 0.6132 - val_loss: 0.8799\n",
      "Epoch 58/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6167 - loss: 0.9043 - val_accuracy: 0.6163 - val_loss: 0.8800\n",
      "Epoch 59/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6219 - loss: 0.8952 - val_accuracy: 0.6153 - val_loss: 0.8801\n",
      "Epoch 60/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6274 - loss: 0.8950 - val_accuracy: 0.6136 - val_loss: 0.8801\n",
      "Epoch 61/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6218 - loss: 0.8907 - val_accuracy: 0.6139 - val_loss: 0.8806\n",
      "Epoch 62/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6152 - loss: 0.9075 - val_accuracy: 0.6174 - val_loss: 0.8792\n",
      "Epoch 63/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6264 - loss: 0.9013 - val_accuracy: 0.6122 - val_loss: 0.8784\n",
      "Epoch 64/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6121 - loss: 0.9020 - val_accuracy: 0.6153 - val_loss: 0.8784\n",
      "Epoch 65/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6256 - loss: 0.8926 - val_accuracy: 0.6115 - val_loss: 0.8789\n",
      "Epoch 66/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6141 - loss: 0.9039 - val_accuracy: 0.6184 - val_loss: 0.8797\n",
      "Epoch 67/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6263 - loss: 0.9006 - val_accuracy: 0.6163 - val_loss: 0.8794\n",
      "Epoch 68/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6211 - loss: 0.9010 - val_accuracy: 0.6195 - val_loss: 0.8796\n",
      "Epoch 69/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6208 - loss: 0.8966 - val_accuracy: 0.6132 - val_loss: 0.8801\n",
      "Epoch 70/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6145 - loss: 0.9016 - val_accuracy: 0.6198 - val_loss: 0.8798\n",
      "Epoch 71/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6200 - loss: 0.8905 - val_accuracy: 0.6146 - val_loss: 0.8796\n",
      "Epoch 72/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6161 - loss: 0.8990 - val_accuracy: 0.6150 - val_loss: 0.8796\n",
      "Epoch 73/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6281 - loss: 0.8964 - val_accuracy: 0.6143 - val_loss: 0.8790\n",
      "Epoch 74/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6126 - loss: 0.8926 - val_accuracy: 0.6219 - val_loss: 0.8814\n",
      "Epoch 75/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6153 - loss: 0.9041 - val_accuracy: 0.6122 - val_loss: 0.8798\n",
      "Epoch 76/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6186 - loss: 0.9006 - val_accuracy: 0.6184 - val_loss: 0.8793\n",
      "Epoch 77/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6176 - loss: 0.8934 - val_accuracy: 0.6181 - val_loss: 0.8787\n",
      "Epoch 78/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6237 - loss: 0.8923 - val_accuracy: 0.6181 - val_loss: 0.8781\n",
      "Epoch 79/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6194 - loss: 0.8955 - val_accuracy: 0.6167 - val_loss: 0.8772\n",
      "Epoch 80/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6180 - loss: 0.8893 - val_accuracy: 0.6143 - val_loss: 0.8785\n",
      "Epoch 81/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6235 - loss: 0.8966 - val_accuracy: 0.6167 - val_loss: 0.8780\n",
      "Epoch 82/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6174 - loss: 0.9017 - val_accuracy: 0.6132 - val_loss: 0.8786\n",
      "Epoch 83/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6227 - loss: 0.8895 - val_accuracy: 0.6188 - val_loss: 0.8779\n",
      "Epoch 84/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6138 - loss: 0.9047 - val_accuracy: 0.6163 - val_loss: 0.8785\n",
      "Epoch 85/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6178 - loss: 0.8849 - val_accuracy: 0.6184 - val_loss: 0.8793\n",
      "Epoch 86/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6181 - loss: 0.9077 - val_accuracy: 0.6122 - val_loss: 0.8795\n",
      "Epoch 87/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6179 - loss: 0.8992 - val_accuracy: 0.6174 - val_loss: 0.8799\n",
      "Epoch 88/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6204 - loss: 0.8856 - val_accuracy: 0.6198 - val_loss: 0.8805\n",
      "Epoch 89/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6171 - loss: 0.9004 - val_accuracy: 0.6163 - val_loss: 0.8793\n",
      "Epoch 90/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6168 - loss: 0.9058 - val_accuracy: 0.6160 - val_loss: 0.8785\n",
      "Epoch 91/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6252 - loss: 0.8885 - val_accuracy: 0.6170 - val_loss: 0.8787\n",
      "Epoch 92/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6138 - loss: 0.8963 - val_accuracy: 0.6157 - val_loss: 0.8786\n",
      "Epoch 93/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6233 - loss: 0.8887 - val_accuracy: 0.6146 - val_loss: 0.8782\n",
      "Epoch 94/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6169 - loss: 0.9037 - val_accuracy: 0.6167 - val_loss: 0.8782\n",
      "Epoch 95/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6241 - loss: 0.8934 - val_accuracy: 0.6118 - val_loss: 0.8787\n",
      "Epoch 96/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6166 - loss: 0.9016 - val_accuracy: 0.6188 - val_loss: 0.8787\n",
      "Epoch 97/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6211 - loss: 0.8923 - val_accuracy: 0.6139 - val_loss: 0.8785\n",
      "Epoch 98/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6189 - loss: 0.8978 - val_accuracy: 0.6167 - val_loss: 0.8775\n",
      "Epoch 99/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6163 - loss: 0.9014 - val_accuracy: 0.6198 - val_loss: 0.8776\n",
      "Epoch 100/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6105 - loss: 0.9058 - val_accuracy: 0.6188 - val_loss: 0.8777\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb174661f70>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_predC = clf.predict(X_test)\n",
    "y_predC=np.argmax(y_predC,axis=1)\n",
    "acc = accuracy_score(y_test, y_predC)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9ZyeosClBrF",
    "outputId": "b9793ceb-a653-406b-a15a-06fdd67b4fa8"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Accuracy: 0.6187673130193906\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.74       633\n",
      "           1       0.55      0.52      0.53       299\n",
      "           2       0.61      0.52      0.56       385\n",
      "           3       0.66      0.74      0.70       610\n",
      "           4       0.52      0.49      0.51       961\n",
      "\n",
      "    accuracy                           0.61      2888\n",
      "   macro avg       0.61      0.61      0.61      2888\n",
      "weighted avg       0.61      0.61      0.61      2888\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Compute F1-scores\n",
    "f1_A = f1_score(y_test, y_predA, average='weighted')\n",
    "f1_B = f1_score(y_test, y_predB, average='weighted')\n",
    "f1_C = f1_score(y_test, y_predC, average='weighted')\n",
    "\n",
    "# Prepare data\n",
    "models = ['Model A (TF-IDF)', 'Model B (Word2Vec)', 'Model C (SapBERT-from-PubMedBERT)']\n",
    "f1_scores = [f1_A, f1_B, f1_C]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7, 5))\n",
    "bars = plt.bar(models, f1_scores)\n",
    "\n",
    "# Add values on top of bars\n",
    "for bar, score in zip(bars, f1_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f\"{score:.3f}\", ha='center', fontsize=10, weight='bold')\n",
    "\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"F1-Score Comparison Across Models\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "ZX3XfZGcfjG3",
    "outputId": "d18f4d61-a826-4d5c-b94c-f76b37660a80"
   },
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  }
 ]
}